<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Trajectory Caching System - Albert Framework</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        
        h1, h2, h3 {
            color: #1976d2;
        }
        
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        
        .subtitle {
            font-size: 1.2em;
            color: #666;
            margin-bottom: 30px;
        }
        
        .hero-stats {
            background: linear-gradient(135deg, #1976d2 0%, #42a5f5 100%);
            color: white;
            padding: 40px;
            border-radius: 12px;
            margin-bottom: 40px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 30px;
            margin-top: 20px;
        }
        
        .stat-box {
            text-align: center;
        }
        
        .stat-number {
            font-size: 3em;
            font-weight: bold;
            display: block;
        }
        
        .stat-label {
            font-size: 1.1em;
            opacity: 0.9;
        }
        
        .performance-table {
            background: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
            margin-bottom: 30px;
            overflow-x: auto;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
        }
        
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #eee;
        }
        
        th {
            background-color: #f8f9fa;
            font-weight: 600;
            color: #1976d2;
        }
        
        .speedup {
            color: #4caf50;
            font-weight: bold;
        }
        
        .diagram-container {
            background: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
            margin-bottom: 30px;
        }
        
        .mermaid {
            text-align: center;
        }
        
        .code-block {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 20px 0;
        }
        
        pre {
            margin: 0;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 14px;
        }
        
        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        
        .feature-card {
            background: white;
            padding: 25px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }
        
        .feature-card h3 {
            margin-top: 0;
            color: #1976d2;
        }
        
        .alert {
            background: #e3f2fd;
            border-left: 4px solid #1976d2;
            padding: 15px 20px;
            margin: 20px 0;
            border-radius: 4px;
        }
        
        .alert-title {
            font-weight: bold;
            margin-bottom: 5px;
        }
        
        .implementation-section {
            background: #f8f9fa;
            padding: 30px;
            border-radius: 8px;
            margin: 30px 0;
        }
        
        .performance-chart {
            margin: 30px 0;
            text-align: center;
        }
        
        .highlight {
            background: #fff3cd;
            padding: 2px 6px;
            border-radius: 3px;
        }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
</head>
<body>
    <h1>Trajectory Caching System</h1>
    <p class="subtitle">PyTorch-Powered Performance Acceleration for Gravitational Physics Simulations</p>
    
    <div class="hero-stats">
        <h2 style="margin-top: 0;">Performance vs. Geodesic Integration</h2>
        <div class="stats-grid">
            <div class="stat-box">
                <span class="stat-number">29,323x</span>
                <span class="stat-label">Faster than RK4 Integration</span>
            </div>
            <div class="stat-box">
                <span class="stat-number">8.6ms</span>
                <span class="stat-label">vs 4+ min computation</span>
            </div>
            <div class="stat-box">
                <span class="stat-number">13,702x</span>
                <span class="stat-label">Average Speedup</span>
            </div>
            <div class="stat-box">
                <span class="stat-number">30.6MB</span>
                <span class="stat-label">Cache for 1M Steps</span>
            </div>
        </div>
    </div>
    
    <h2>Overview</h2>
    <p>The Albert framework's trajectory caching system leverages PyTorch's efficient tensor serialization to provide dramatic performance improvements over direct geodesic integration. By intelligently caching computed trajectories from our RK4 geodesic solvers, we transform multi-minute calculations into millisecond operations.</p>
    
    <div class="performance-table">
        <h3>Cache Performance vs. Geodesic Integration</h3>
        <table>
            <thead>
                <tr>
                    <th>Trajectory Steps</th>
                    <th>Geodesic Integration<br/>(First Run)</th>
                    <th>Cached Load<br/>(Subsequent Runs)</th>
                    <th>Speedup</th>
                    <th>Cache Size</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>10,000</td>
                    <td>2.75 s<br/><small>RK4 integration</small></td>
                    <td>2.5 ms<br/><small>PyTorch load</small></td>
                    <td class="speedup">1,109.9x</td>
                    <td>~0.3 MB</td>
                </tr>
                <tr>
                    <td>100,000</td>
                    <td>25.80 s<br/><small>RK4 integration</small></td>
                    <td>2.4 ms<br/><small>PyTorch load</small></td>
                    <td class="speedup">10,673.7x</td>
                    <td>~3.1 MB</td>
                </tr>
                <tr>
                    <td>1,000,000</td>
                    <td>4m 12.7s<br/><small>RK4 integration</small></td>
                    <td>8.6 ms<br/><small>PyTorch load</small></td>
                    <td class="speedup">29,323.3x</td>
                    <td>~30.6 MB</td>
                </tr>
            </tbody>
        </table>
        <p style="margin-top: 15px; font-size: 0.9em; color: #666;">
            <strong>Note:</strong> Geodesic integration times are from solving the full geodesic equations using our RK4 integrators 
            (GeodesicRK4Solver, GeneralGeodesicRK4Solver, etc.) with adaptive step sizing and constraint preservation.
        </p>
    </div>
    
    <h2>How It Works</h2>
    
    <div class="diagram-container">
        <h3>Cache Architecture</h3>
        <div class="mermaid">
            graph TB
                subgraph "Trajectory Request"
                    R[Request<br/>Theory, r‚ÇÄ, steps, ŒîœÑ]
                end
                
                subgraph "Cache System"
                    H[Hash Generator<br/>SHA256]
                    C{Cache<br/>Check}
                    L[Load from Disk<br/>~2-10ms]
                    S[Save to Disk]
                end
                
                subgraph "Geodesic Integration (Avoided)"
                    G[Solver Selection<br/>4D/6D/Charged/Quantum]
                    RK4[RK4 Integration<br/>10K-1M steps]
                    CH[Christoffel Symbols<br/>40 components]
                    CN[Constraint Preservation<br/>Energy, Angular Momentum]
                    T[Total Time:<br/>2s - 4+ min]
                end
                
                subgraph "Results"
                    RES[Return Trajectory<br/>+ Tag + Kicks]
                end
                
                R --> H
                H --> C
                C -->|Hit ‚úì| L
                C -->|Miss ‚úó| G
                G --> RK4
                RK4 --> CH
                CH --> CN
                CN --> T
                T --> S
                S --> RES
                L --> RES
                
                style L fill:#90EE90
                style T fill:#FFB6C1
                style RES fill:#87CEEB
                style G fill:#FFE4B5
                style RK4 fill:#FFE4B5
                style CH fill:#FFE4B5
                style CN fill:#FFE4B5
        </div>
    </div>
    
    <h2>What Computation Does the Cache Avoid?</h2>
    
    <div class="implementation-section">
        <h3>The Expensive Geodesic Integration Process</h3>
        <p>When computing trajectories without caching, the system must perform the following expensive operations:</p>
        
        <div class="feature-grid">
            <div class="feature-card">
                <h3>üî¢ RK4 Integration Steps</h3>
                <p>For each of the 10,000 to 1,000,000+ time steps:</p>
                <ul>
                    <li>Evaluate metric tensor g<sub>ŒºŒΩ</sub>(r,Œ∏,œÜ)</li>
                    <li>Compute 4 RK4 sub-steps (k‚ÇÅ, k‚ÇÇ, k‚ÇÉ, k‚ÇÑ)</li>
                    <li>Update position and velocity</li>
                    <li>Adaptive step size control</li>
                </ul>
                <p><strong>Cost:</strong> O(N) where N = number of steps</p>
            </div>
            
            <div class="feature-card">
                <h3>üìê Christoffel Symbols</h3>
                <p>At each integration step, compute:</p>
                <ul>
                    <li>40 independent Christoffel symbols</li>
                    <li>Œì<sup>Œº</sup><sub>ŒΩœÅ</sub> = ¬Ωg<sup>ŒºœÉ</sup>(‚àÇ<sub>ŒΩ</sub>g<sub>œÉœÅ</sub> + ...)</li>
                    <li>Metric derivatives via autograd</li>
                    <li>Tensor contractions</li>
                </ul>
                <p><strong>Cost:</strong> 40 √ó N tensor operations</p>
            </div>
            
            <div class="feature-card">
                <h3>‚öñÔ∏è Constraint Preservation</h3>
                <p>Maintain physical constraints:</p>
                <ul>
                    <li>Energy conservation: E = constant</li>
                    <li>Angular momentum: L<sub>z</sub> = constant</li>
                    <li>4-velocity normalization: g<sub>ŒºŒΩ</sub>u<sup>Œº</sup>u<sup>ŒΩ</sup> = -c¬≤</li>
                    <li>Numerical stability checks</li>
                </ul>
                <p><strong>Cost:</strong> Additional computations per step</p>
            </div>
        </div>
        
        <div class="alert" style="margin-top: 20px;">
            <div class="alert-title">Computational Complexity</div>
            <p>A 1-million step trajectory requires:</p>
            <ul style="margin-top: 10px;">
                <li>‚Ä¢ 1,000,000 metric evaluations</li>
                <li>‚Ä¢ 4,000,000 RK4 sub-steps</li>
                <li>‚Ä¢ 40,000,000 Christoffel symbol computations</li>
                <li>‚Ä¢ Continuous constraint checking</li>
            </ul>
            <p style="margin-top: 10px;">The cache replaces all of this with a <strong>single 8.6ms tensor load</strong> from disk!</p>
        </div>
    </div>
    
    <h2>PyTorch Integration</h2>
    
    <div class="implementation-section">
        <h3>Leveraging PyTorch's Tensor Serialization</h3>
        <p>The caching system takes advantage of PyTorch's highly optimized tensor serialization format:</p>
        
        <div class="code-block">
            <pre>def save_trajectory(self, trajectory: Tensor, cache_path: str, dtype: torch.dtype) -> bool:
    """Save computed trajectory using PyTorch's efficient binary format."""
    # PyTorch automatically handles:
    # - Efficient binary encoding
    # - Metadata preservation (shape, dtype, device)
    # - Compression of sparse regions
    # - Memory-mapped file support
    torch.save(trajectory.to(dtype=dtype), cache_path)
    
def load_trajectory(self, cache_path: str, device: torch.device) -> Optional[Tensor]:
    """Load trajectory with near-zero overhead."""
    # PyTorch's load() provides:
    # - Direct memory mapping
    # - Lazy loading capabilities
    # - Automatic device placement
    return torch.load(cache_path, map_location=device)</pre>
        </div>
    </div>
    
    <h2>Key Features</h2>
    
    <div class="feature-grid">
        <div class="feature-card">
            <h3>üîë Intelligent Hashing</h3>
            <p>SHA256-based cache keys ensure uniqueness based on:</p>
            <ul>
                <li>Theory name and parameters</li>
                <li>Initial radius (r‚ÇÄ)</li>
                <li>Number of steps</li>
                <li>Time step size (ŒîœÑ)</li>
                <li>Particle properties (mass, charge, spin)</li>
                <li>Theory-specific parameters</li>
            </ul>
        </div>
        
        <div class="feature-card">
            <h3>üíæ Persistent Storage</h3>
            <p>Cache survives across:</p>
            <ul>
                <li>Multiple runs</li>
                <li>Engine instances</li>
                <li>Python sessions</li>
                <li>System reboots</li>
            </ul>
            <p>Version-controlled to prevent stale data issues.</p>
        </div>
        
        <div class="feature-card">
            <h3>üöÄ Zero-Configuration</h3>
            <p>Automatic operation:</p>
            <ul>
                <li>No manual cache management</li>
                <li>Transparent to user code</li>
                <li>Self-organizing file structure</li>
                <li>Automatic cleanup of old versions</li>
            </ul>
        </div>
    </div>
    
    <div class="alert">
        <div class="alert-title">Performance Scaling</div>
        <p>The cache provides increasingly dramatic benefits as trajectory length increases. For million-step trajectories, the speedup exceeds <span class="highlight">29,000x</span>, transforming 4+ minute computations into 8.6ms operations.</p>
    </div>
    
    <h2>Implementation Example</h2>
    
    <div class="code-block">
        <pre># Basic usage - caching is automatic
from physics_agent.theory_engine_core import TheoryEngine
from physics_agent.theories.defaults.baselines.schwarzschild import Schwarzschild

engine = TheoryEngine()
theory = Schwarzschild()

# First run: computes trajectory (e.g., 4 minutes for 1M steps)
hist, tag, kicks = engine.run_trajectory(
    theory, 
    r0=295338.39,     # 100 Schwarzschild radii
    n_steps=1_000_000,
    dtau=0.01
)
print(f"Tag: {tag}")  # Output: "symmetric_solver_run"

# Second run: loads from cache (8.6ms for 1M steps!)
hist2, tag2, kicks2 = engine.run_trajectory(
    theory, 
    r0=295338.39,
    n_steps=1_000_000,
    dtau=0.01
)
print(f"Tag: {tag2}")  # Output: "cached_trajectory"

# Speedup: 29,323x! üöÄ</pre>
    </div>
    
    <h2>Cache Management</h2>
    
    <div class="code-block">
        <pre>from physics_agent.cache import TrajectoryCache

cache = TrajectoryCache()

# Get cache statistics
for root, dirs, files in os.walk(cache.trajectories_dir):
    for f in files:
        if f.endswith('.pt'):
            size = os.path.getsize(os.path.join(root, f)) / 1e6
            print(f"{f}: {size:.1f} MB")

# Clear cache if needed
cache.clear_cache(confirm=True)

# Clean up old versions
cache.clear_old_cache()</pre>
    </div>
    
    <h2>Use Cases</h2>
    
    <div class="performance-table">
        <h3>Real-World Applications</h3>
        <table>
            <thead>
                <tr>
                    <th>Use Case</th>
                    <th>Without Cache<br/>(Geodesic Integration)</th>
                    <th>With Cache<br/>(PyTorch Load)</th>
                    <th>Benefit</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Parameter Sweep (100 runs)</td>
                    <td>400 minutes<br/><small>100 √ó RK4 integration</small></td>
                    <td>4.99 minutes<br/><small>1 √ó RK4 + 99 √ó cache</small></td>
                    <td>80x faster research iteration</td>
                </tr>
                <tr>
                    <td>Multi-Validator Testing</td>
                    <td>Recompute geodesics<br/><small>for each validator</small></td>
                    <td>Single computation<br/><small>shared across all</small></td>
                    <td>N validators = N√ó speedup</td>
                </tr>
                <tr>
                    <td>Interactive Visualization</td>
                    <td>4+ minute wait<br/><small>per trajectory change</small></td>
                    <td>8.6ms load<br/><small>instant updates</small></td>
                    <td>Real-time exploration</td>
                </tr>
                <tr>
                    <td>CI/CD Pipeline</td>
                    <td>Hours per run<br/><small>solving geodesics</small></td>
                    <td>Minutes per run<br/><small>using cache</small></td>
                    <td>Faster development cycles</td>
                </tr>
            </tbody>
        </table>
    </div>
    
    <h2>Technical Details</h2>
    
    <div class="implementation-section">
        <h3>Cache File Format</h3>
        <p>Example cache filename:</p>
        <div class="code-block">
            <pre>Schwarzschild_r0-295338.39_steps-1000000_dt-0.0000_dtype-float64_efd37783b162.pt</pre>
        </div>
        
        <p>Components:</p>
        <ul>
            <li><strong>Theory name:</strong> Schwarzschild</li>
            <li><strong>Initial radius:</strong> r0-295338.39 (in meters)</li>
            <li><strong>Steps:</strong> 1000000</li>
            <li><strong>Time step:</strong> dt-0.0000</li>
            <li><strong>Data type:</strong> float64</li>
            <li><strong>Hash suffix:</strong> efd37783b162 (first 12 chars of SHA256)</li>
        </ul>
        
        <h3>Storage Efficiency</h3>
        <p>PyTorch tensor storage provides:</p>
        <ul>
            <li>Compact binary representation</li>
            <li>Automatic handling of tensor metadata</li>
            <li>Support for memory-mapped loading</li>
            <li>Cross-platform compatibility</li>
        </ul>
    </div>
    
    <div class="alert" style="margin-top: 40px;">
        <div class="alert-title">Bottom Line</div>
        <p>A <strong>30MB cache investment</strong> yields a <strong>13,702x average performance return</strong>. For production workloads, parameter optimization, and interactive research, the trajectory caching system is not just beneficial‚Äîit's essential.</p>
    </div>
</body>
</html> 